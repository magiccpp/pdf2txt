{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "\n",
    "\n",
    "def docx_to_text_with_images(docx_path, output_text_path, image_folder='images'):\n",
    "    os.makedirs(image_folder, exist_ok=True)\n",
    "    document = Document(docx_path)\n",
    "    all_text = []\n",
    "\n",
    "    image_counter = 1\n",
    "    image_dict = {}\n",
    "\n",
    "    \n",
    "    # Extract all images and prepare them to be inserted as placeholders\n",
    "    for rel in document.part.rels.values():\n",
    "        if \"image\" in rel.target_ref:\n",
    "            img_part = rel.target_part\n",
    "            img_blob = img_part.blob\n",
    "            img_format = os.path.splitext(img_part.partname)[1][1:]  # e.g., 'png', 'jpeg'\n",
    "\n",
    "            # Save the image\n",
    "            image_name = f\"img_{image_counter}.{img_format}\"\n",
    "            image_path = os.path.join(image_folder, image_name)\n",
    "            with open(image_path, 'wb') as image_file:\n",
    "                image_file.write(img_blob)\n",
    "\n",
    "            # Associate relationship ID with image name for placeholders\n",
    "            image_dict[rel.rId] = image_name\n",
    "            image_counter += 1\n",
    "\n",
    "    # Insert text with image placeholders\n",
    "    for paragraph in document.paragraphs:\n",
    "        print('1111111111111111')\n",
    "        print(paragraph.text)\n",
    "        paragraph_text = []\n",
    "        for run in paragraph.runs:\n",
    "            \n",
    "            paragraph_text.append(run.text)\n",
    "            # Instead of looking for a:blip, we loop over document level images as placeholders\n",
    "            embedded_images = [\n",
    "                f\"[Image: {image_dict[embed]}]\"\n",
    "                for embed in image_dict if embed in run._element.xml\n",
    "            ]\n",
    "            paragraph_text.extend(embedded_images)\n",
    "\n",
    "        all_text.append(''.join(paragraph_text))\n",
    "\n",
    "    # Write all combined text with placeholders to the output file\n",
    "    with open(output_text_path, 'w', encoding='utf-8') as text_file:\n",
    "        text_file.write('\\n\\n'.join(all_text))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    docx_path = \"words/1706.03762v7.docx\"       # Path to the DOCX file\n",
    "    output_text_path = \"output-doc.txt\"      # Path for the output text file\n",
    "    docx_to_text_with_images(docx_path, output_text_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "from docx.oxml.ns import qn\n",
    "\n",
    "def docx_to_text_with_hyperlinks(docx_path, output_text_path, image_folder='images'):\n",
    "    os.makedirs(image_folder, exist_ok=True)\n",
    "    document = Document(docx_path)\n",
    "    all_pages = []\n",
    "    current_page = []\n",
    "\n",
    "    # Hyperlink dictionary\n",
    "    hyperlink_dict = {rel.rId: rel.target_ref for rel in document.part.rels.values() if rel.is_external}\n",
    "    \n",
    "    paragraph_count = 0\n",
    "\n",
    "    for paragraph in document.paragraphs:\n",
    "        paragraph_text = []\n",
    "        paragraph_xml = paragraph._element\n",
    "\n",
    "        for run in paragraph.runs:\n",
    "            run_xml = run._element\n",
    "\n",
    "            # Check each run for a hyperlink\n",
    "            hyperlink = run_xml.find('.//{}'.format(qn('w:hyperlink')))\n",
    "            if hyperlink is not None:\n",
    "                r_id = hyperlink.get(qn('r:id'))\n",
    "                text_content = run.text\n",
    "                if r_id in hyperlink_dict:\n",
    "                    hyperlink_ref = hyperlink_dict[r_id]\n",
    "                    # Format with hyperlink text preserved\n",
    "                    text_content += f\" (Link: {hyperlink_ref})\"\n",
    "            \n",
    "            # Append the run text to paragraph_text\n",
    "            paragraph_text.append(run.text)\n",
    "\n",
    "        content = ''.join(paragraph_text).strip()\n",
    "        if content:\n",
    "            current_page.append(content)\n",
    "\n",
    "        paragraph_count += 1\n",
    "\n",
    "        # Arbitrary decision point for page breaking; adjust if needed\n",
    "        if paragraph_count >= 20:\n",
    "            all_pages.append(' '.join(current_page))\n",
    "            current_page = []\n",
    "            paragraph_count = 0\n",
    "\n",
    "    # Add any remaining content as the last page\n",
    "    if current_page:\n",
    "        all_pages.append(' '.join(current_page))\n",
    "\n",
    "    # Write all pages to the output file\n",
    "    with open(output_text_path, 'w', encoding='utf-8') as text_file:\n",
    "        for i, page_content in enumerate(all_pages, 1):\n",
    "            text_file.write(f\"--- Page {i} ---\\n{page_content}\\n\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    docx_path = \"words/1706.03762v7.docx\"       # Path to the DOCX file\n",
    "    output_text_path = \"output-doc.txt\"      # Path for the output text file\n",
    "    docx_to_text_with_hyperlinks(docx_path, output_text_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "from docx.oxml.shared import qn\n",
    "from docx.opc.constants import RELATIONSHIP_TYPE as RT\n",
    "\n",
    "def extract_paragraph_text(paragraph):\n",
    "    text_parts = []\n",
    "    in_field = False\n",
    "    for run in paragraph.runs:\n",
    "        if run.element.find('.//w:fldChar[@w:fldCharType=\"begin\"]', namespaces=run.element.nsmap) is not None:\n",
    "            in_field = True\n",
    "            text_parts.append('<REF>')\n",
    "        elif run.element.find('.//w:fldChar[@w:fldCharType=\"end\"]', namespaces=run.element.nsmap) is not None:\n",
    "            in_field = False\n",
    "            text_parts.append('</REF>')\n",
    "        else:\n",
    "            text_parts.append(run.text)\n",
    "        \n",
    "        # Check for hyperlinks\n",
    "        hyperlink = run._element.find('.//{}'.format(qn('w:hyperlink')))\n",
    "        if hyperlink is not None:\n",
    "            r_id = hyperlink.get(qn('r:id'))\n",
    "            if r_id in hyperlink_dict:\n",
    "                hyperlink_ref = hyperlink_dict[r_id]\n",
    "                text_parts[-1] = f\"{text_parts[-1]} (Link: {hyperlink_ref})\"\n",
    "    \n",
    "    return ''.join(text_parts)\n",
    "\n",
    "def docx_to_text_with_images_and_links(docx_path, output_text_path, image_folder='images'):\n",
    "    os.makedirs(image_folder, exist_ok=True)\n",
    "    document = Document(docx_path)\n",
    "    all_pages = []\n",
    "    current_page = []\n",
    "\n",
    "    image_counter = 1\n",
    "    image_dict = {}\n",
    "    hyperlink_dict = {}\n",
    "\n",
    "    # Extract all images and hyperlinks\n",
    "    for rel in document.part.rels.values():\n",
    "        if \"image\" in rel.target_ref:\n",
    "            img_part = rel.target_part\n",
    "            img_blob = img_part.blob\n",
    "            img_format = os.path.splitext(img_part.partname)[1][1:]  # e.g., 'png', 'jpeg'\n",
    "\n",
    "            # Save the image\n",
    "            image_name = f\"img_{image_counter}.{img_format}\"\n",
    "            image_path = os.path.join(image_folder, image_name)\n",
    "            with open(image_path, 'wb') as image_file:\n",
    "                image_file.write(img_blob)\n",
    "\n",
    "            # Associate relationship ID with image name for placeholders\n",
    "            image_dict[rel.rId] = image_name\n",
    "            image_counter += 1\n",
    "        \n",
    "        if rel.is_external:\n",
    "            hyperlink_dict[rel.rId] = rel.target_ref\n",
    "    \n",
    "    paragraph_count = 0\n",
    "\n",
    "    for paragraph in document.paragraphs:\n",
    "        paragraph_text = extract_paragraph_text(paragraph)\n",
    "        \n",
    "        # Handle embedded images\n",
    "        for embed in image_dict:\n",
    "            if embed in paragraph._element.xml:\n",
    "                image_name = image_dict[embed]\n",
    "                if embed in hyperlink_dict:\n",
    "                    hyperlink_ref = hyperlink_dict[embed]\n",
    "                    paragraph_text += f\" [Image: {image_name} (Link: {hyperlink_ref})]\"\n",
    "                else:\n",
    "                    paragraph_text += f\" [Image: {image_name}]\"\n",
    "\n",
    "        if paragraph_text.strip():\n",
    "            current_page.append(paragraph_text)\n",
    "\n",
    "        paragraph_count += 1\n",
    "\n",
    "        # Arbitrary decision point for page breaking; adjust if needed\n",
    "        if paragraph_count >= 20:\n",
    "            all_pages.append(' '.join(current_page))\n",
    "            current_page = []\n",
    "            paragraph_count = 0\n",
    "\n",
    "    # Add any remaining content as the last page\n",
    "    if current_page:\n",
    "        all_pages.append(' '.join(current_page))\n",
    "\n",
    "    # Write all pages to the output file\n",
    "    with open(output_text_path, 'w', encoding='utf-8') as text_file:\n",
    "        for i, page_content in enumerate(all_pages, 1):\n",
    "            text_file.write(f\"--- Page {i} ---\\n{page_content}\\n\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    docx_path = \"words/1706.03762v7.docx\"\n",
    "    output_text_path = \"output-doc.txt\"\n",
    "    docx_to_text_with_images_and_links(docx_path, output_text_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
